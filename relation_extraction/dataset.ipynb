{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interim-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pdb\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "sys.path.append('../../')\n",
    "from utils import EntityMarker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "original-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"CP 학습을 위한 데이터셋 클래스.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, path, args):\n",
    "        \"\"\"tokenized sentence 초기화, CP를 위한 positive pair 생성\n",
    "        \n",
    "        Args:\n",
    "            path: dataset 경로\n",
    "            args: command line args\n",
    "        \n",
    "        Returns:\n",
    "            반환하는 값은 존재하지 않음\n",
    "        \n",
    "        Raises:\n",
    "            경로에 있는 dataset이 prepare_data.py에 나타난 형태가 아니면,\n",
    "                - 'key not found'\n",
    "                - 'integer can't be indexed'\n",
    "                와 같은 에러 발생\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.args = args\n",
    "        data = json.load(open(os.path.join(path, \"cpdata.json\")))\n",
    "        rel2scope = json.load(open(os.path.join(path, \"rel2scope.json\")))\n",
    "        entityMarker = EntityMarker()\n",
    "        \n",
    "        self.tokens = np.zeros((len(data), args.max_length), dtype=int)\n",
    "        self.mask = np.zeros((len(data), args.max_length), dtype=int)\n",
    "        self.label = np.zeros((len(data)), dtype=int)\n",
    "        self.h_pos = np.zeros((len(data)), dtype=int)\n",
    "        self.t_pos = np.zeros((len(data)), dtype=int)\n",
    "        \n",
    "        # distant supervised label\n",
    "        # label이 같은 문장은 positive pair, 그렇지 않으면 negative pair\n",
    "        for i, rel in enumerate(rel2scope.keys()):\n",
    "            scope = rel2scope[rel]\n",
    "            for j in range(scope[0], scope[1]):\n",
    "                self.label[j] = i\n",
    "                \n",
    "        for i, sentence in enumerate(data):\n",
    "            h_flag = random.random() > args.alpha\n",
    "            t_flag = random.random() > args.alpha\n",
    "            h_p = sentence[\"h\"][\"pos\"][0]     # [10,11,12] 형태\n",
    "            t_p = sentence[\"t\"][\"pos\"][0]     # [18, 19] 형태\n",
    "            ids, ph, pt = entityMarker.tokenize(sentence[\"tokens\"], [h_p[0], h_p[-1]+1], [t_p[0], t_p[-1]+1], None, None, h_flag, t_flag)\n",
    "            length = min(len(ids), args.max_length)\n",
    "            self.tokens[i][:length] = ids[:length]\n",
    "            self.mask[i][:length] = 1\n",
    "            self.h_pos[i] = min(args.max_length - 1, ph)\n",
    "            self.t_pos[i] = min(args.max_length - 1, pt)\n",
    "        print(\"The number of sentence in which tokenizer can't find head/tail entity is %d\" % entityMarker.err)\n",
    "        \n",
    "        # sample positive pair dynamically\n",
    "        self.__sample__()\n",
    "    \n",
    "    def __pos_pair__(self, scope):\n",
    "        \"\"\"positive pair 생성\n",
    "        \n",
    "        Args:\n",
    "            scope: label이 같은 문장의 인덱스 범위\n",
    "                example: [0, 12]\n",
    "        \n",
    "        Returns:\n",
    "            all_pos_pair: 모든 positive pairs를 반환.\n",
    "            \n",
    "            ********\n",
    "            같은 범위 안에 존재하는 문장 쌍은 모두 positive pair이므로,\n",
    "            N = scope[1] - scope[0]이라 할 때 (N-1)N/2개의 쌍이 존재.\n",
    "            개수가 N^2에 비례하므로 데이터 사이의 불균형이 발생.\n",
    "            이를 해결하기 위해 N에 비례하도록 positive pair를 sampling한다.\n",
    "            epoch이 달라질 때마다 sentence pair를 다시 sampling, i.e. dynamic sampling.\n",
    "        \"\"\"\n",
    "        pos_scope = list(range(scope[0], scope[1]))\n",
    "        \n",
    "        # shuffle\n",
    "        random.shuffle(pos_scope)\n",
    "        all_pos_pair = []\n",
    "        bag = []\n",
    "        for i, index in enumerate(pos_scope):\n",
    "            bag.append(index)\n",
    "            if (i+1) % 2 == 0:\n",
    "                all_pos_pair.append(bag)\n",
    "                bag = []\n",
    "        return all_pos_pair\n",
    "        \n",
    "    def __sample__(self):\n",
    "        \"\"\"Samples positive pairs.\n",
    "        \n",
    "        Sampling 후에, 'self.pos_pair'는 all pairs sampled.\n",
    "        'self.pos_pair' example:\n",
    "            [\n",
    "                [0, 2],\n",
    "                [1, 6],\n",
    "                [12, 25],\n",
    "                ...\n",
    "            ]\n",
    "        \n",
    "        \"\"\"\n",
    "        rel2scope = json.load(open(os.path.join(self.path, \"rel2scope.json\")))\n",
    "        self.pos_pair = []\n",
    "        for rel in rel2scope.keys():\n",
    "            scope = rel2scope[rel]\n",
    "            pos_pair = self.__pos_pair__(scope)\n",
    "            self.pos_pair.extend(pos_pair)\n",
    "        \n",
    "        print(\"Positive pair's number is %d\" % len(self.pos_pair))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of instances in an epoch.        \n",
    "        \"\"\"\n",
    "        return len(self.pos_pair)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get training instance.\n",
    "        \n",
    "        Args:\n",
    "            index: Instance index.\n",
    "            \n",
    "        Returns:\n",
    "            input: Tokenized word id\n",
    "            mask: Attention mask for bert. 0 means masking, 1 means not masking\n",
    "            label: label for sentence\n",
    "            h_pos: head entity 위치\n",
    "            t_pos: tail entity 위치\n",
    "        \"\"\"\n",
    "        bag = self.pos_pair[index]\n",
    "        input = np.zeros(self.args.max_length * 2, dtype=int)\n",
    "        mask = np.zeros(self.args.max_length * 2, dtype=int)\n",
    "        label = np.zeros(2, dtype=int)\n",
    "        h_pos = np.zeros(2, dtype=int)\n",
    "        t_pos = np.zeros(2, dtype=int)\n",
    "        \n",
    "        for i, ind in enumerate(bag):\n",
    "            input[i * self.args.max_length:(i+1) * self.args.max_length] = self.tokens[ind]\n",
    "            mask[i * self.args.max_length:(i+1) * self.args.max_length] = self.mask[ind]\n",
    "            label[i] = self.label[ind]\n",
    "            h_pos[i] = self.h_pos[ind]\n",
    "            t_pos[i] = self.t_pos[ind]\n",
    "        \n",
    "        return input, mask, label, h_pos, t_pos\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "approved-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTBDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"MTB 학습을 위한 데이터셋 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, args):\n",
    "        \"\"\"Tokenized 문장 초기화 및 MTB를 위한 positive pair 생성.\n",
    "        \n",
    "        Args:\n",
    "            path: dataset 경로\n",
    "            args: command line args\n",
    "        \n",
    "        Returns:\n",
    "            반환하는 값은 존재하지 않음\n",
    "            \n",
    "        Raises:\n",
    "            경로에 있는 dataset이 prepare_data.py에 나타난 형태가 아니면,\n",
    "                - 'key not found'\n",
    "                - 'integer can't be indexed'\n",
    "                와 같은 에러 발생\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.args = args\n",
    "        data = json.load(open(os.path.join(path, \"mtbdata.json\")))\n",
    "        entityMarker = EntityMarker()\n",
    "        \n",
    "        # important configures\n",
    "        tot_sentence = len(data)\n",
    "        \n",
    "        \n",
    "        # token들을 id로 바꾸고 몇 개의 entity를 random하게 blank로 바꿔준다.\n",
    "        self.tokens = np.zeros((tot_sentence, args.max_length), dtype=int)\n",
    "        self.mask = np.zeros((tot_sentence, args.max_length), dtype=int)\n",
    "        self.h_pos = np.zeros(tot_sentence, dtype=int)\n",
    "        self.t_pos = np.zeros(tot_sentence, dtype=int)\n",
    "        \n",
    "        for i, sentence in enumerate(data):\n",
    "            h_flag = random.random() > args.alpha\n",
    "            t_flag = random.random() > args.alpha\n",
    "            h_p = sentence[\"h\"][\"pos\"][0]\n",
    "            t_p = sentence[\"t\"][\"pos\"][0]\n",
    "            ids, ph, pt = entityMarker.tokenize(sentence[\"tokens\"], [h_p[0], h_p[-1]+1], [t_p[0], t_p[-1]+1],\n",
    "                                                None, None, h_flag, t_flag)\n",
    "            length = min(len(ids), args.max_length)\n",
    "            self.tokens[i][0:length] = ids[0:length]\n",
    "            self.mask[i][0:length] = 1\n",
    "            self.h_pos[i] = min(args.max_length - 1, ph)\n",
    "            self.t_pos[i] = min(args.max_length - 1, pt)\n",
    "            \n",
    "        print(\"The number of sentence in which tokenizer can't find head/tail entity is %d\" % entityMarker.err)\n",
    "\n",
    "        entpair2scope = json.load(open(os.path.join(path, \"entpair2scope.json\")))\n",
    "        entpair2negpair = json.load(open(os.path.join(path, \"entpair2negpair.json\")))\n",
    "        self.pos_pair = []\n",
    "        \n",
    "        for key in entpair2scope.keys():\n",
    "            scope = entpair2scope[key]\n",
    "            pos_pair = self.__pos_pair__(scope)\n",
    "            self.pos_pair.extend(pos_pair)\n",
    "        print(\"Positive pairs' number is %d\" % len(self.pos_pair))\n",
    "        \n",
    "        # sample negative pairs dynamically\n",
    "        self.__sample__()\n",
    "        \n",
    "    def __sample__(self):\n",
    "        \"\"\"negative pairs를 sampling하는 함수.\n",
    "        \n",
    "        entpair2negpair는 dictionary 형태로 key가 head_id#tail_id 형태이고,\n",
    "        value는 head나 entity 둘 중 하나만 다른 형태\n",
    "        \n",
    "        *********\n",
    "        negative pair의 수가 positive pair의 수와 같은 만큼 sampling 수행\n",
    "        \"\"\"\n",
    "        entpair2scope = json.load(open(os.path.join(path, \"entpair2scope.json\")))\n",
    "        entpair2negpair = json.load(open(os.path.join(path, \"entpair2negpair.json\")))\n",
    "        neg_pair = []\n",
    "        \n",
    "        # get all negative pairs\n",
    "        for key in entpair2negpair.keys():\n",
    "            my_scope = entpair2scope[key]\n",
    "            entpairs = entpair2negpair[key]\n",
    "            if len(entpairs) == 0:\n",
    "                continue\n",
    "            for entpair in entpairs:\n",
    "                neg_scope = entpair2scope[entpair]\n",
    "                neg_pair.extend(self.__neg_pair__(my_scope, neg_scope))\n",
    "        print(\"(MTB)Negative pairs number is %d\" % len(neg_pair))\n",
    "        \n",
    "        # positive pair와 같은 수만큼 negative pair sampling\n",
    "        random.shuffle(neg_pair)\n",
    "        self.neg_pair = neg_pair[0:len(self.pos_pair)]\n",
    "        del neg_pair   # save the memory\n",
    "          \n",
    "    def __pos_pair__(self, scope):\n",
    "        \"\"\"하나의 scope에 대해 positive pair를 생성하는 함수.\n",
    "        \n",
    "        Args:\n",
    "            scope: 같은 entity pair를 가지는 문장의 scope\n",
    "        \n",
    "        Returns:\n",
    "            pos_pair: scope 안에 있는 모든 positive pair를 반환.\n",
    "        \"\"\"\n",
    "        ent_scope = list(range(scope[0], scope[1]))\n",
    "        pos_pair = []\n",
    "        \n",
    "        for i in range(len(ent_scope)):\n",
    "            for j in range(i+1, len(ent_scope)):\n",
    "                pos_pair.append([ent_scope[i], ent_scope[j]])\n",
    "        return pos_pair   \n",
    "    \n",
    "    def __neg_pair__(self, my_scope, neg_scope):\n",
    "        \"\"\"다른 scope에 있는 negative pair를 생성하는 함수.\n",
    "        \n",
    "        Args:\n",
    "            my_scope: negative pair에 대해 기준이 되는 문장이 담긴 scope\n",
    "            neg_scope: negative pair들이 모두 담긴 scope\n",
    "        \n",
    "        Returns:\n",
    "            neg_pair: 모든 negative pairs의 scope를 반환.\n",
    "        \"\"\"\n",
    "        my_scope = list(range(my_scope[0], my_scope[1]))\n",
    "        neg_scope = list(range(neg_scope[0], neg_scope[1]))\n",
    "        neg_pair = []\n",
    "        for i in my_scope:\n",
    "            for j in neg_scope:\n",
    "                neg_pair.append([i, j])\n",
    "        return neg_pair    \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of instances in an epoch.        \n",
    "        \"\"\"\n",
    "        return len(self.pos_pair)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Gets training instance.\n",
    "        \n",
    "        index가 홀수이면, negative instance를 반환하고 짝수이면 positive instance를 반환.\n",
    "        batch에서는 positive pairs의 수와 negative pairs의 수가 같아짐.\n",
    "        \n",
    "        Args:\n",
    "            index: Data index\n",
    "            \n",
    "        Returns:\n",
    "            {l,h}_input: Tokenized word id.\n",
    "            {l,h}_mask: Attention mask for bert.\n",
    "            {l,h}_ph: head entity 위치\n",
    "            {l,h}_pt: tail entity 위치\n",
    "            label: positive 또는 negative\n",
    "            \n",
    "        \"\"\"\n",
    "        if index % 2 == 0:\n",
    "            l_ind = self.pos_pair[index][0]\n",
    "            r_ind = self.pos_pair[index][1]\n",
    "            label = 1\n",
    "        else:\n",
    "            l_ind = self.neg_pair[index][0]\n",
    "            r_ind = self.neg_pair[index][1]\n",
    "            label = 0\n",
    "        \n",
    "        l_input = self.tokens[l_ind]\n",
    "        l_mask = self.mask[l_ind]\n",
    "        l_ph = self.h_pos[l_ind]\n",
    "        l_pt = self.t_pos[l_ind]\n",
    "        r_input = self.tokens[r_ind]\n",
    "        r_mask = self.mask[r_ind]\n",
    "        r_ph = self.h_pos[r_ind]\n",
    "        r_pt = self.t_pos[r_ind]\n",
    "        \n",
    "        return l_input, l_mask, l_ph, l_pt, r_input, r_mask, r_ph, r_pt, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "false-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [5, 15], [5, 16], [5, 17], [5, 18], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [6, 15], [6, 16], [6, 17], [6, 18], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 17], [7, 18], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [8, 15], [8, 16], [8, 17], [8, 18], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14], [9, 15], [9, 16], [9, 17], [9, 18], [10, 11], [10, 12], [10, 13], [10, 14], [10, 15], [10, 16], [10, 17], [10, 18], [11, 12], [11, 13], [11, 14], [11, 15], [11, 16], [11, 17], [11, 18], [12, 13], [12, 14], [12, 15], [12, 16], [12, 17], [12, 18], [13, 14], [13, 15], [13, 16], [13, 17], [13, 18], [14, 15], [14, 16], [14, 17], [14, 18], [15, 16], [15, 17], [15, 18], [16, 17], [16, 18], [17, 18]]\n"
     ]
    }
   ],
   "source": [
    "ent_scope = list(range(5, 19))\n",
    "pos_pair = []\n",
    "for i in range(len(ent_scope)):\n",
    "    for j in range(i+1, len(ent_scope)):\n",
    "        pos_pair.append([ent_scope[i], ent_scope[j]])\n",
    "print(pos_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "israeli-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tribal-valve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "through-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.extend([[8, 10], [1, 11], [4, 14], [2, 6], [9, 3], [12, 7], [13, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "animated-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.extend([[21, 19], [26, 16], [27, 23], [29, 22], [18, 15], [25, 17], [24, 20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "associate-genome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 10],\n",
       " [1, 11],\n",
       " [4, 14],\n",
       " [2, 6],\n",
       " [9, 3],\n",
       " [12, 7],\n",
       " [13, 5],\n",
       " [21, 19],\n",
       " [26, 16],\n",
       " [27, 23],\n",
       " [29, 22],\n",
       " [18, 15],\n",
       " [25, 17],\n",
       " [24, 20]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personalized-certificate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25, 17],\n",
       " [2, 6],\n",
       " [21, 19],\n",
       " [27, 23],\n",
       " [4, 14],\n",
       " [24, 20],\n",
       " [26, 16],\n",
       " [18, 15],\n",
       " [13, 5],\n",
       " [1, 11],\n",
       " [8, 10],\n",
       " [29, 22],\n",
       " [9, 3],\n",
       " [12, 7]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reliable-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pospair(scope):\n",
    "    pos_scope = list(range(scope[0], scope[1]))\n",
    "    \n",
    "    random.shuffle(pos_scope)\n",
    "    all_pos_pair = []\n",
    "    bag = []\n",
    "    for i, index in enumerate(pos_scope):\n",
    "        bag.append(index)\n",
    "        if (i+1) % 2 == 0:\n",
    "            all_pos_pair.append(bag)\n",
    "            bag = []\n",
    "    return all_pos_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vertical-conditions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 26], [19, 16], [25, 17], [20, 24], [22, 28], [18, 27], [21, 29]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pospair([15,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pleased-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/CP/'\n",
    "data = json.load(open(os.path.join(path, 'cpdata.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affiliated-grounds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773307"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "industrial-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['The',\n",
       "  'converse',\n",
       "  'is',\n",
       "  'not',\n",
       "  'in',\n",
       "  'general',\n",
       "  'true',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'Kodaira',\n",
       "  'embedding',\n",
       "  'theorem',\n",
       "  'gives',\n",
       "  'a',\n",
       "  'criterion',\n",
       "  'for',\n",
       "  'a',\n",
       "  'Kähler',\n",
       "  'manifold',\n",
       "  'to',\n",
       "  'be',\n",
       "  'projective',\n",
       "  '.'],\n",
       " 'h': {'id': 'Q6425088',\n",
       "  'name': 'kodaira embedding theorem',\n",
       "  'pos': [[10, 11, 12]]},\n",
       " 'r': 'P2384',\n",
       " 't': {'id': 'Q1353916', 'name': 'kähler manifold', 'pos': [[18, 19]]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valid-navigation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['The',\n",
       "  'Hodge',\n",
       "  'index',\n",
       "  'theorem',\n",
       "  'was',\n",
       "  'a',\n",
       "  'result',\n",
       "  'on',\n",
       "  'the',\n",
       "  'intersection',\n",
       "  'number',\n",
       "  'theory',\n",
       "  'for',\n",
       "  'curves',\n",
       "  'on',\n",
       "  'an',\n",
       "  'algebraic',\n",
       "  'surface',\n",
       "  ':',\n",
       "  'it',\n",
       "  'determines',\n",
       "  'the',\n",
       "  'signature',\n",
       "  'of',\n",
       "  'the',\n",
       "  'corresponding',\n",
       "  'quadratic',\n",
       "  'form',\n",
       "  '.'],\n",
       " 'h': {'id': 'Q5876058', 'name': 'hodge index theorem', 'pos': [[1, 2, 3]]},\n",
       " 'r': 'P2384',\n",
       " 't': {'id': 'Q1434805', 'name': 'algebraic surface', 'pos': [[16, 17]]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "absolute-tracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((len(data)), dtype=int)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aware-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2scope = json.load(open(os.path.join(path, \"rel2scope.json\")))\n",
    "label = np.zeros(len(data), dtype=int)\n",
    "for i, rel in enumerate(rel2scope.keys()):\n",
    "    scope = rel2scope[rel]\n",
    "    for j in range(scope[0], scope[1]):\n",
    "        label[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "light-continent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 697, 697, 697])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "upper-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel2scope.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tough-sherman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "grateful-course",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-private",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
